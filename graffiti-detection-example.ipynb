{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graffiti detection using roboflow dataset and YoloV8\n",
    "\n",
    "This notebook serves as a guide to train and use a the yolov8 model to detect graffiti, in order to do that we will use the ultralytics version of yolov8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before we start working with the model ...\n",
    "\n",
    "If you had the previous version of the scraper and collected the data with it, you might like to execute the next cells in order to change the names of the images to just the image name instead of the real path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "old_data = pd.read_csv(\"./links_and_file_names.csv\")\n",
    "\n",
    "old_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\usuario\\\\Desktop\\\\Personal projects\\\\ML-Projects\\\\graffiti analysis\\\\graffiti-analysis\\\\images\\\\img_0.jpg'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_data[\"img_name\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\usuario\\\\Desktop\\\\Personal projects\\\\ML-Projects\\\\graffiti analysis\\\\graffiti-analysis\\\\'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pathlib\n",
    "from os import path\n",
    "\n",
    "newpath = f\"{str(pathlib.Path().absolute())}\\\\\"\n",
    "# pahtlib returns the file location using a c instead of a C\n",
    "newpath = 'C'+ newpath[1:len(newpath)]\n",
    "newpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img_0.jpg'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = old_data[\"img_name\"][0]\n",
    "a.removeprefix(newpath + \"images\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link_to_img</th>\n",
       "      <th>img_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://live.staticflickr.com/3813/11280349214...</td>\n",
       "      <td>img_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://live.staticflickr.com/3902/14681887286...</td>\n",
       "      <td>img_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://live.staticflickr.com/197/441199812_21...</td>\n",
       "      <td>img_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://live.staticflickr.com/65535/5098186973...</td>\n",
       "      <td>img_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://live.staticflickr.com/7849/45972882765...</td>\n",
       "      <td>img_4.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         link_to_img   img_name\n",
       "0  https://live.staticflickr.com/3813/11280349214...  img_0.jpg\n",
       "1  https://live.staticflickr.com/3902/14681887286...  img_1.jpg\n",
       "2  https://live.staticflickr.com/197/441199812_21...  img_2.jpg\n",
       "3  https://live.staticflickr.com/65535/5098186973...  img_3.jpg\n",
       "4  https://live.staticflickr.com/7849/45972882765...  img_4.jpg"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_data[\"img_name\"] = old_data[\"img_name\"].map(lambda x: x.removeprefix(newpath + \"images\\\\\"))\n",
    "\n",
    "old_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_data.to_csv(str(path.join(newpath, 'links_and_file_names.csv')), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to training the model\n",
    "\n",
    "First we use only the data available on the [roboflow dataset](https://universe.roboflow.com/sumanthrao369/graffiti-collab), in order to do that go to the link and then download the zip file for yolov8. After downloading the dataset and unzipping it, now the only thing left to do is to import the yolov8 from the ultralytics library and train it with the yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't execute this cell unless you have an 8GB GPU or better, it would be best if you trained your model on colab and then exported it and use it afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.19 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.18  Python-3.11.0 torch-2.3.0+cu118 CUDA:0 (NVIDIA GeForce 930MX, 2048MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=c:\\Users\\usuario\\Desktop\\Personal projects\\ML-Projects\\graffiti analysis\\graffiti-analysis\\runs\\detect\\train5\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011043 parameters, 3011027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\usuario\\Desktop\\Personal projects\\ML-Projects\\graffiti analysis\\graffiti-analysis\\datasets\\train\\labels.cache... 896 images, 0 backgrounds, 0 corrupt: 100%|██████████| 896/896 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\usuario\\Desktop\\Personal projects\\ML-Projects\\graffiti analysis\\graffiti-analysis\\datasets\\train\\images\\01soda2003b_jpg.rf.c2fc92241a77a19726ac22ff58043f40.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\usuario\\Desktop\\Personal projects\\ML-Projects\\graffiti analysis\\graffiti-analysis\\datasets\\train\\images\\0_mast_nyc_2012_jpg.rf.7026432863d0cc350cf06080ddbc2727.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\usuario\\Desktop\\Personal projects\\ML-Projects\\graffiti analysis\\graffiti-analysis\\datasets\\train\\images\\1_yes_nyc_2012_jpg.rf.91793ae1510a17b62247bf6a4b37ccf2.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\usuario\\Desktop\\Personal projects\\ML-Projects\\graffiti analysis\\graffiti-analysis\\datasets\\train\\images\\1zeto_klovn_jpg.rf.73943b007b3343c457538156c5e54a83.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\usuario\\Desktop\\Personal projects\\ML-Projects\\graffiti analysis\\graffiti-analysis\\datasets\\train\\images\\photo_0abb4cdd760ccf77b8a94e4f5622895b62c86dc1_jpg.rf.abc9215693179b64bdab00e9ce3884cd.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\usuario\\Desktop\\Personal projects\\ML-Projects\\graffiti analysis\\graffiti-analysis\\datasets\\train\\images\\photo_0ac77193ff3d0a9a63640b71924924ab89fda783_jpg.rf.9efde80fee46543ad253102473fb9441.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\usuario\\Desktop\\Personal projects\\ML-Projects\\graffiti analysis\\graffiti-analysis\\datasets\\train\\images\\photo_0df083df00d02da71f567d52938ca875dda2fa3f_jpg.rf.797b80b9c5d40eea5c52f52d77a4b261.jpg: 1 duplicate labels removed\n",
      "WARNING  Box and segment counts should be equal, but got len(segments) = 2703, len(boxes) = 2704. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\usuario\\Desktop\\Personal projects\\ML-Projects\\graffiti analysis\\graffiti-analysis\\datasets\\valid\\labels.cache... 257 images, 0 backgrounds, 0 corrupt: 100%|██████████| 257/257 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Box and segment counts should be equal, but got len(segments) = 754, len(boxes) = 758. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "results = model.train(data=\"data.yaml\", epochs=100, imgsz=640, device = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the pretrained model is used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# from pretrained\n",
    "\n",
    "model = YOLO(\"best.torchscript\", task=\"detect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 c:\\Users\\usuario\\Desktop\\Personal projects\\ML-Projects\\graffiti analysis\\graffiti-analysis\\images\\img_2199.jpg: 640x640 1 graffiti, 308.0ms\n",
      "Speed: 167.0ms preprocess, 308.0ms inference, 128.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(\"images/img_2199.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[0].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
